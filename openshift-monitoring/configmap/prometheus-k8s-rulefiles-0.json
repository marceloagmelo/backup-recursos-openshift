{"kind":"ConfigMap","apiVersion":"v1","metadata":{"name":"prometheus-k8s-rulefiles-0","namespace":"openshift-monitoring","selfLink":"/api/v1/namespaces/openshift-monitoring/configmaps/prometheus-k8s-rulefiles-0","uid":"9c5f73cd-c124-11e9-9cc2-42010a9e0002","resourceVersion":"367349","creationTimestamp":"2019-08-17T19:24:19Z","labels":{"managed-by":"prometheus-operator","prometheus-name":"k8s"},"ownerReferences":[{"apiVersion":"monitoring.coreos.com/v1","kind":"Prometheus","name":"k8s","uid":"4e671a30-a716-11e9-9411-42010a9e0002","controller":true,"blockOwnerDeletion":true}]},"data":{"openshift-monitoring-prometheus-k8s-rules.yaml":"groups:\n- name: k8s.rules\n  rules:\n  - expr: |\n      sum(rate(container_cpu_usage_seconds_total{job=\"kubelet\", image!=\"\", container_name!=\"\"}[5m])) by (namespace)\n    record: namespace:container_cpu_usage_seconds_total:sum_rate\n  - expr: |\n      sum by (namespace, pod_name, container_name) (\n        rate(container_cpu_usage_seconds_total{job=\"kubelet\", image!=\"\", container_name!=\"\"}[5m])\n      )\n    record: namespace_pod_name_container_name:container_cpu_usage_seconds_total:sum_rate\n  - expr: |\n      sum(container_memory_usage_bytes{job=\"kubelet\", image!=\"\", container_name!=\"\"}) by (namespace)\n    record: namespace:container_memory_usage_bytes:sum\n  - expr: |\n      sum by (namespace, label_name) (\n         sum(rate(container_cpu_usage_seconds_total{job=\"kubelet\", image!=\"\", container_name!=\"\"}[5m])) by (namespace, pod_name)\n       * on (namespace, pod_name) group_left(label_name)\n         label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    record: namespace_name:container_cpu_usage_seconds_total:sum_rate\n  - expr: |\n      sum by (namespace, label_name) (\n        sum(container_memory_usage_bytes{job=\"kubelet\",image!=\"\", container_name!=\"\"}) by (pod_name, namespace)\n      * on (namespace, pod_name) group_left(label_name)\n        label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    record: namespace_name:container_memory_usage_bytes:sum\n  - expr: |\n      sum by (namespace, label_name) (\n        sum(kube_pod_container_resource_requests_memory_bytes{job=\"kube-state-metrics\"}) by (namespace, pod)\n      * on (namespace, pod) group_left(label_name)\n        label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    record: namespace_name:kube_pod_container_resource_requests_memory_bytes:sum\n  - expr: |\n      sum by (namespace, label_name) (\n        sum(kube_pod_container_resource_requests_cpu_cores{job=\"kube-state-metrics\"} and on(pod) kube_pod_status_scheduled{condition=\"true\"}) by (namespace, pod)\n      * on (namespace, pod) group_left(label_name)\n        label_replace(kube_pod_labels{job=\"kube-state-metrics\"}, \"pod_name\", \"$1\", \"pod\", \"(.*)\")\n      )\n    record: namespace_name:kube_pod_container_resource_requests_cpu_cores:sum\n- name: kube-scheduler.rules\n  rules:\n  - expr: |\n      histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.99\"\n    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.99\"\n    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.99\"\n    record: cluster_quantile:scheduler_binding_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.9\"\n    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.9\"\n    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.9\"\n    record: cluster_quantile:scheduler_binding_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.5\"\n    record: cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.5\"\n    record: cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile\n  - expr: |\n      histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job=\"kube-controllers\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.5\"\n    record: cluster_quantile:scheduler_binding_latency:histogram_quantile\n- name: kube-apiserver.rules\n  rules:\n  - expr: |\n      histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.99\"\n    record: cluster_quantile:apiserver_request_latencies:histogram_quantile\n  - expr: |\n      histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.9\"\n    record: cluster_quantile:apiserver_request_latencies:histogram_quantile\n  - expr: |\n      histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job=\"apiserver\"}[5m])) without(instance, pod)) / 1e+06\n    labels:\n      quantile: \"0.5\"\n    record: cluster_quantile:apiserver_request_latencies:histogram_quantile\n- name: node.rules\n  rules:\n  - expr: sum(min(kube_pod_info) by (node))\n    record: ':kube_pod_info_node_count:'\n  - expr: |\n      max(label_replace(kube_pod_info{job=\"kube-state-metrics\"}, \"pod\", \"$1\", \"pod\", \"(.*)\")) by (node, namespace, pod)\n    record: 'node_namespace_pod:kube_pod_info:'\n  - expr: |\n      count by (node) (sum by (node, cpu) (\n        node_cpu{job=\"node-exporter\"}\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      ))\n    record: node:node_num_cpu:sum\n  - expr: |\n      1 - avg(rate(node_cpu{job=\"node-exporter\",mode=\"idle\"}[1m]))\n    record: :node_cpu_utilisation:avg1m\n  - expr: |\n      1 - avg by (node) (\n        rate(node_cpu{job=\"node-exporter\",mode=\"idle\"}[1m])\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:)\n    record: node:node_cpu_utilisation:avg1m\n  - expr: |\n      sum(node_load1{job=\"node-exporter\"})\n      /\n      sum(node:node_num_cpu:sum)\n    record: ':node_cpu_saturation_load1:'\n  - expr: |\n      sum by (node) (\n        node_load1{job=\"node-exporter\"}\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n      /\n      node:node_num_cpu:sum\n    record: 'node:node_cpu_saturation_load1:'\n  - expr: |\n      1 -\n      sum(node_memory_MemFree{job=\"node-exporter\"} + node_memory_Cached{job=\"node-exporter\"} + node_memory_Buffers{job=\"node-exporter\"})\n      /\n      sum(node_memory_MemTotal{job=\"node-exporter\"})\n    record: ':node_memory_utilisation:'\n  - expr: |\n      sum(node_memory_MemFree{job=\"node-exporter\"} + node_memory_Cached{job=\"node-exporter\"} + node_memory_Buffers{job=\"node-exporter\"})\n    record: :node_memory_MemFreeCachedBuffers:sum\n  - expr: |\n      sum(node_memory_MemTotal{job=\"node-exporter\"})\n    record: :node_memory_MemTotal:sum\n  - expr: |\n      sum by (node) (\n        (node_memory_MemFree{job=\"node-exporter\"} + node_memory_Cached{job=\"node-exporter\"} + node_memory_Buffers{job=\"node-exporter\"})\n        * on (namespace, pod) group_left(node)\n          node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_memory_bytes_available:sum\n  - expr: |\n      sum by (node) (\n        node_memory_MemTotal{job=\"node-exporter\"}\n        * on (namespace, pod) group_left(node)\n          node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_memory_bytes_total:sum\n  - expr: |\n      (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)\n      /\n      scalar(sum(node:node_memory_bytes_total:sum))\n    record: node:node_memory_utilisation:ratio\n  - expr: |\n      1e3 * sum(\n        (rate(node_vmstat_pgpgin{job=\"node-exporter\"}[1m])\n       + rate(node_vmstat_pgpgout{job=\"node-exporter\"}[1m]))\n      )\n    record: :node_memory_swap_io_bytes:sum_rate\n  - expr: |\n      1 -\n      sum by (node) (\n        (node_memory_MemFree{job=\"node-exporter\"} + node_memory_Cached{job=\"node-exporter\"} + node_memory_Buffers{job=\"node-exporter\"})\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n      /\n      sum by (node) (\n        node_memory_MemTotal{job=\"node-exporter\"}\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n    record: 'node:node_memory_utilisation:'\n  - expr: |\n      1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)\n    record: 'node:node_memory_utilisation_2:'\n  - expr: |\n      1e3 * sum by (node) (\n        (rate(node_vmstat_pgpgin{job=\"node-exporter\"}[1m])\n       + rate(node_vmstat_pgpgout{job=\"node-exporter\"}[1m]))\n       * on (namespace, pod) group_left(node)\n         node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_memory_swap_io_bytes:sum_rate\n  - expr: |\n      avg(irate(node_disk_io_time_ms{job=\"node-exporter\",device=~\"(sd|xvd|nvme).+\"}[1m]) / 1e3)\n    record: :node_disk_utilisation:avg_irate\n  - expr: |\n      avg by (node) (\n        irate(node_disk_io_time_ms{job=\"node-exporter\",device=~\"(sd|xvd|nvme).+\"}[1m]) / 1e3\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_disk_utilisation:avg_irate\n  - expr: |\n      avg(irate(node_disk_io_time_weighted{job=\"node-exporter\",device=~\"(sd|xvd|nvme).+\"}[1m]) / 1e3)\n    record: :node_disk_saturation:avg_irate\n  - expr: |\n      avg by (node) (\n        irate(node_disk_io_time_weighted{job=\"node-exporter\",device=~\"(sd|xvd|nvme).+\"}[1m]) / 1e3\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_disk_saturation:avg_irate\n  - expr: |\n      max by (namespace, pod, device) ((node_filesystem_size{fstype=~\"ext[234]|btrfs|xfs|zfs\"}\n      - node_filesystem_avail{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n      / node_filesystem_size{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n    record: 'node:node_filesystem_usage:'\n  - expr: |\n      max by (namespace, pod, device) (node_filesystem_avail{fstype=~\"ext[234]|btrfs|xfs|zfs\"} / node_filesystem_size{fstype=~\"ext[234]|btrfs|xfs|zfs\"})\n    record: 'node:node_filesystem_avail:'\n  - expr: |\n      sum(irate(node_network_receive_bytes{job=\"node-exporter\",device=\"eth0\"}[1m])) +\n      sum(irate(node_network_transmit_bytes{job=\"node-exporter\",device=\"eth0\"}[1m]))\n    record: :node_net_utilisation:sum_irate\n  - expr: |\n      sum by (node) (\n        (irate(node_network_receive_bytes{job=\"node-exporter\",device=\"eth0\"}[1m]) +\n        irate(node_network_transmit_bytes{job=\"node-exporter\",device=\"eth0\"}[1m]))\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_net_utilisation:sum_irate\n  - expr: |\n      sum(irate(node_network_receive_drop{job=\"node-exporter\",device=\"eth0\"}[1m])) +\n      sum(irate(node_network_transmit_drop{job=\"node-exporter\",device=\"eth0\"}[1m]))\n    record: :node_net_saturation:sum_irate\n  - expr: |\n      sum by (node) (\n        (irate(node_network_receive_drop{job=\"node-exporter\",device=\"eth0\"}[1m]) +\n        irate(node_network_transmit_drop{job=\"node-exporter\",device=\"eth0\"}[1m]))\n      * on (namespace, pod) group_left(node)\n        node_namespace_pod:kube_pod_info:\n      )\n    record: node:node_net_saturation:sum_irate\n- name: kube-prometheus-node-recording.rules\n  rules:\n  - expr: sum(rate(node_cpu{mode!=\"idle\",mode!=\"iowait\"}[3m])) BY (instance)\n    record: instance:node_cpu:rate:sum\n  - expr: sum((node_filesystem_size{mountpoint=\"/\"} - node_filesystem_free{mountpoint=\"/\"}))\n      BY (instance)\n    record: instance:node_filesystem_usage:sum\n  - expr: sum(rate(node_network_receive_bytes[3m])) BY (instance)\n    record: instance:node_network_receive_bytes:rate:sum\n  - expr: sum(rate(node_network_transmit_bytes[3m])) BY (instance)\n    record: instance:node_network_transmit_bytes:rate:sum\n  - expr: sum(rate(node_cpu{mode!=\"idle\",mode!=\"iowait\"}[5m])) WITHOUT (cpu, mode)\n      / ON(instance) GROUP_LEFT() count(sum(node_cpu) BY (instance, cpu)) BY (instance)\n    record: instance:node_cpu:ratio\n  - expr: sum(rate(node_cpu{mode!=\"idle\",mode!=\"iowait\"}[5m]))\n    record: cluster:node_cpu:sum_rate5m\n  - expr: cluster:node_cpu:rate5m / count(sum(node_cpu) BY (instance, cpu))\n    record: cluster:node_cpu:ratio\n- name: node_exporter-16-bcache\n  rules:\n  - expr: node_bcache_cache_read_races\n    record: node_bcache_cache_read_races_total\n- name: node_exporter-16-buddyinfo\n  rules:\n  - expr: node_buddyinfo_blocks\n    record: node_buddyinfo_count\n- name: node_exporter-16-stat\n  rules:\n  - expr: node_boot_time_seconds\n    record: node_boot_time\n  - expr: node_context_switches_total\n    record: node_context_switches\n  - expr: node_forks_total\n    record: node_forks\n  - expr: node_intr_total\n    record: node_intr\n- name: node_exporter-16-cpu\n  rules:\n  - expr: label_replace(node_cpu_seconds_total, \"cpu\", \"$1\", \"cpu\", \"cpu(.+)\")\n    record: node_cpu\n- name: node_exporter-16-diskstats\n  rules:\n  - expr: node_disk_read_bytes_total\n    record: node_disk_bytes_read\n  - expr: node_disk_written_bytes_total\n    record: node_disk_bytes_written\n  - expr: node_disk_io_time_seconds_total * 1000\n    record: node_disk_io_time_ms\n  - expr: node_disk_io_time_weighted_seconds_total\n    record: node_disk_io_time_weighted\n  - expr: node_disk_reads_completed_total\n    record: node_disk_reads_completed\n  - expr: node_disk_reads_merged_total\n    record: node_disk_reads_merged\n  - expr: node_disk_read_time_seconds_total * 1000\n    record: node_disk_read_time_ms\n  - expr: node_disk_writes_completed_total\n    record: node_disk_writes_completed\n  - expr: node_disk_writes_merged_total\n    record: node_disk_writes_merged\n  - expr: node_disk_write_time_seconds_total * 1000\n    record: node_disk_write_time_ms\n- name: node_exporter-16-filesystem\n  rules:\n  - expr: node_filesystem_free_bytes\n    record: node_filesystem_free\n  - expr: node_filesystem_avail_bytes\n    record: node_filesystem_avail\n  - expr: node_filesystem_size_bytes\n    record: node_filesystem_size\n- name: node_exporter-16-infiniband\n  rules:\n  - expr: node_infiniband_port_data_received_bytes_total\n    record: node_infiniband_port_data_received_bytes\n  - expr: node_infiniband_port_data_transmitted_bytes_total\n    record: node_infiniband_port_data_transmitted_bytes\n- name: node_exporter-16-interrupts\n  rules:\n  - expr: node_interrupts_total\n    record: node_interrupts\n- name: node_exporter-16-memory\n  rules:\n  - expr: node_memory_Active_bytes\n    record: node_memory_Active\n  - expr: node_memory_Active_anon_bytes\n    record: node_memory_Active_anon\n  - expr: node_memory_Active_file_bytes\n    record: node_memory_Active_file\n  - expr: node_memory_AnonHugePages_bytes\n    record: node_memory_AnonHugePages\n  - expr: node_memory_AnonPages_bytes\n    record: node_memory_AnonPages\n  - expr: node_memory_Bounce_bytes\n    record: node_memory_Bounce\n  - expr: node_memory_Buffers_bytes\n    record: node_memory_Buffers\n  - expr: node_memory_Cached_bytes\n    record: node_memory_Cached\n  - expr: node_memory_CommitLimit_bytes\n    record: node_memory_CommitLimit\n  - expr: node_memory_Committed_AS_bytes\n    record: node_memory_Committed_AS\n  - expr: node_memory_DirectMap2M_bytes\n    record: node_memory_DirectMap2M\n  - expr: node_memory_DirectMap4k_bytes\n    record: node_memory_DirectMap4k\n  - expr: node_memory_Dirty_bytes\n    record: node_memory_Dirty\n  - expr: node_memory_HardwareCorrupted_bytes\n    record: node_memory_HardwareCorrupted\n  - expr: node_memory_Hugepagesize_bytes\n    record: node_memory_Hugepagesize\n  - expr: node_memory_Inactive_bytes\n    record: node_memory_Inactive\n  - expr: node_memory_Inactive_anon_bytes\n    record: node_memory_Inactive_anon\n  - expr: node_memory_Inactive_file_bytes\n    record: node_memory_Inactive_file\n  - expr: node_memory_KernelStack_bytes\n    record: node_memory_KernelStack\n  - expr: node_memory_Mapped_bytes\n    record: node_memory_Mapped\n  - expr: node_memory_MemAvailable_bytes\n    record: node_memory_MemAvailable\n  - expr: node_memory_MemFree_bytes\n    record: node_memory_MemFree\n  - expr: node_memory_MemTotal_bytes\n    record: node_memory_MemTotal\n  - expr: node_memory_Mlocked_bytes\n    record: node_memory_Mlocked\n  - expr: node_memory_NFS_Unstable_bytes\n    record: node_memory_NFS_Unstable\n  - expr: node_memory_PageTables_bytes\n    record: node_memory_PageTables\n  - expr: node_memory_Shmem_bytes\n    record: node_memory_Shmem\n  - expr: node_memory_Slab_bytes\n    record: node_memory_Slab\n  - expr: node_memory_SReclaimable_bytes\n    record: node_memory_SReclaimable\n  - expr: node_memory_SUnreclaim_bytes\n    record: node_memory_SUnreclaim\n  - expr: node_memory_SwapCached_bytes\n    record: node_memory_SwapCached\n  - expr: node_memory_SwapFree_bytes\n    record: node_memory_SwapFree\n  - expr: node_memory_SwapTotal_bytes\n    record: node_memory_SwapTotal\n  - expr: node_memory_Unevictable_bytes\n    record: node_memory_Unevictable\n  - expr: node_memory_VmallocChunk_bytes\n    record: node_memory_VmallocChunk\n  - expr: node_memory_VmallocTotal_bytes\n    record: node_memory_VmallocTotal\n  - expr: node_memory_VmallocUsed_bytes\n    record: node_memory_VmallocUsed\n  - expr: node_memory_Writeback_bytes\n    record: node_memory_Writeback\n  - expr: node_memory_WritebackTmp_bytes\n    record: node_memory_WritebackTmp\n- name: node_exporter-16-network\n  rules:\n  - expr: node_network_receive_bytes_total\n    record: node_network_receive_bytes\n  - expr: node_network_receive_compressed_total\n    record: node_network_receive_compressed\n  - expr: node_network_receive_drop_total\n    record: node_network_receive_drop\n  - expr: node_network_receive_errs_total\n    record: node_network_receive_errs\n  - expr: node_network_receive_fifo_total\n    record: node_network_receive_fifo\n  - expr: node_network_receive_frame_total\n    record: node_network_receive_frame\n  - expr: node_network_receive_multicast_total\n    record: node_network_receive_multicast\n  - expr: node_network_receive_packets_total\n    record: node_network_receive_packets\n  - expr: node_network_transmit_bytes_total\n    record: node_network_transmit_bytes\n  - expr: node_network_transmit_compressed_total\n    record: node_network_transmit_compressed\n  - expr: node_network_transmit_drop_total\n    record: node_network_transmit_drop\n  - expr: node_network_transmit_errs_total\n    record: node_network_transmit_errs\n  - expr: node_network_transmit_fifo_total\n    record: node_network_transmit_fifo\n  - expr: node_network_transmit_frame_total\n    record: node_network_transmit_frame\n  - expr: node_network_transmit_multicast_total\n    record: node_network_transmit_multicast\n  - expr: node_network_transmit_packets_total\n    record: node_network_transmit_packets\n- name: node_exporter-16-nfs\n  rules:\n  - expr: node_nfs_connections_total\n    record: node_nfs_net_connections\n  - expr: node_nfs_packets_total\n    record: node_nfs_net_reads\n  - expr: label_replace(label_replace(node_nfs_requests_total, \"proto\", \"$1\", \"version\",\n      \"(.+)\"), \"method\", \"$1\", \"procedure\", \"(.+)\")\n    record: node_nfs_procedures\n  - expr: node_nfs_rpc_authentication_refreshes_total\n    record: node_nfs_rpc_authentication_refreshes\n  - expr: node_nfs_rpcs_total\n    record: node_nfs_rpc_operations\n  - expr: node_nfs_rpc_retransmissions_total\n    record: node_nfs_rpc_retransmissions\n- name: node_exporter-16-textfile\n  rules:\n  - expr: node_textfile_mtime_seconds\n    record: node_textfile_mtime\n- name: kubernetes.rules\n  rules:\n  - expr: sum(container_memory_usage_bytes{container_name!=\"POD\",pod_name!=\"\"}) BY\n      (pod_name, namespace)\n    record: pod_name:container_memory_usage_bytes:sum\n  - expr: sum(container_spec_cpu_shares{container_name!=\"POD\",pod_name!=\"\"}) BY (pod_name,\n      namespace)\n    record: pod_name:container_spec_cpu_shares:sum\n  - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=\"POD\",pod_name!=\"\"}[5m]))\n      BY (pod_name, namespace)\n    record: pod_name:container_cpu_usage:sum\n  - expr: sum(container_fs_usage_bytes{container_name!=\"POD\",pod_name!=\"\"}) BY (pod_name,\n      namespace)\n    record: pod_name:container_fs_usage_bytes:sum\n  - expr: sum(container_memory_usage_bytes{container_name!=\"\"}) BY (namespace)\n    record: namespace:container_memory_usage_bytes:sum\n  - expr: sum(container_spec_cpu_shares{container_name!=\"\"}) BY (namespace)\n    record: namespace:container_spec_cpu_shares:sum\n  - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=\"POD\"}[5m]))\n      BY (namespace)\n    record: namespace:container_cpu_usage:sum\n  - expr: sum(container_memory_usage_bytes{container_name!=\"POD\",pod_name!=\"\"}) BY\n      (cluster) / sum(machine_memory_bytes) BY (cluster)\n    record: cluster:memory_usage:ratio\n  - expr: sum(container_spec_cpu_shares{container_name!=\"POD\",pod_name!=\"\"}) / 1000\n      / sum(machine_cpu_cores)\n    record: cluster:container_spec_cpu_shares:ratio\n  - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=\"POD\",pod_name!=\"\"}[5m]))\n      / sum(machine_cpu_cores)\n    record: cluster:container_cpu_usage:ratio\n  - alert: ClusterMonitoringOperatorErrors\n    annotations:\n      message: Cluster Monitoring Operator is experiencing {{ printf \"%0.0f\" $value\n        }}% errors.\n    expr: sum(rate(cluster_monitoring_operator_reconcile_errors_total[15m])) * 100\n      / sum(rate(cluster_monitoring_operator_reconcile_attempts_total[15m])) \u003e 10\n    for: 15m\n    labels:\n      severity: critical\n- name: openshift-build.rules\n  rules:\n  - expr: sum(openshift_build_total{job=\"kubernetes-apiservers\",phase=\"Error\"})/(sum(openshift_build_total{job=\"kubernetes-apiservers\",phase=~\"Failed|Complete|Error\"}))\n    record: build_error_rate\n- name: kubernetes-absent\n  rules:\n  - alert: AlertmanagerDown\n    annotations:\n      message: Alertmanager has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"alertmanager-main\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: ClusterMonitoringOperatorDown\n    annotations:\n      message: ClusterMonitoringOperator has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"cluster-monitoring-operator\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeAPIDown\n    annotations:\n      message: KubeAPI has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"apiserver\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeControllerManagerDown\n    annotations:\n      message: KubeControllerManager has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"kube-controllers\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeSchedulerDown\n    annotations:\n      message: KubeScheduler has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"kube-controllers\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeStateMetricsDown\n    annotations:\n      message: KubeStateMetrics has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"kube-state-metrics\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeletDown\n    annotations:\n      message: Kubelet has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"kubelet\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: NodeExporterDown\n    annotations:\n      message: NodeExporter has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"node-exporter\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: PrometheusDown\n    annotations:\n      message: Prometheus has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"prometheus-k8s\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n  - alert: PrometheusOperatorDown\n    annotations:\n      message: PrometheusOperator has disappeared from Prometheus target discovery.\n    expr: |\n      absent(up{job=\"prometheus-operator\"} == 1)\n    for: 15m\n    labels:\n      severity: critical\n- name: kubernetes-apps\n  rules:\n  - alert: KubePodCrashLooping\n    annotations:\n      message: '{{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }})\n        is restarting {{ printf \"%.2f\" $value }} / second'\n    expr: |\n      rate(kube_pod_container_status_restarts_total{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}[15m]) \u003e 0\n    for: 1h\n    labels:\n      severity: critical\n  - alert: KubePodNotReady\n    annotations:\n      message: '{{ $labels.namespace }}/{{ $labels.pod }} is not ready.'\n    expr: |\n      sum by (namespace, pod) (kube_pod_status_phase{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\", phase=~\"Pending|Unknown\"}) \u003e 0\n    for: 1h\n    labels:\n      severity: critical\n  - alert: KubeDeploymentGenerationMismatch\n    annotations:\n      message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} generation\n        mismatch\n    expr: |\n      kube_deployment_status_observed_generation{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        !=\n      kube_deployment_metadata_generation{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeDeploymentReplicasMismatch\n    annotations:\n      message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} replica\n        mismatch\n    expr: |\n      kube_deployment_spec_replicas{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        !=\n      kube_deployment_status_replicas_available{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n    for: 1h\n    labels:\n      severity: critical\n  - alert: KubeStatefulSetReplicasMismatch\n    annotations:\n      message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} replica\n        mismatch\n    expr: |\n      kube_statefulset_status_replicas_ready{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        !=\n      kube_statefulset_status_replicas{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeStatefulSetGenerationMismatch\n    annotations:\n      message: StatefulSet {{ $labels.namespace }}/{{ labels.statefulset }} generation\n        mismatch\n    expr: |\n      kube_statefulset_status_observed_generation{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        !=\n      kube_statefulset_metadata_generation{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeDaemonSetRolloutStuck\n    annotations:\n      message: Only {{$value}}% of desired pods scheduled and ready for daemon set\n        {{$labels.namespace}}/{{$labels.daemonset}}\n    expr: |\n      kube_daemonset_status_number_ready{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        /\n      kube_daemonset_status_desired_number_scheduled{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"} * 100 \u003c 100\n    for: 15m\n    labels:\n      severity: critical\n  - alert: KubeDaemonSetNotScheduled\n    annotations:\n      message: A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}}\n        are not scheduled.\n    expr: |\n      kube_daemonset_status_desired_number_scheduled{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}\n        -\n      kube_daemonset_status_current_number_scheduled{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"} \u003e 0\n    for: 10m\n    labels:\n      severity: warning\n  - alert: KubeDaemonSetMisScheduled\n    annotations:\n      message: A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}}\n        are running where they are not supposed to run.\n    expr: |\n      kube_daemonset_status_number_misscheduled{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"} \u003e 0\n    for: 10m\n    labels:\n      severity: warning\n  - alert: KubeCronJobRunning\n    annotations:\n      message: CronJob {{ $labels.namespaces }}/{{ $labels.cronjob }} is taking more\n        than 1h to complete.\n    expr: |\n      time() - kube_cronjob_next_schedule_time{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"} \u003e 3600\n    for: 1h\n    labels:\n      severity: warning\n  - alert: KubeJobCompletion\n    annotations:\n      message: Job {{ $labels.namespaces }}/{{ $labels.job }} is taking more than\n        1h to complete.\n    expr: |\n      kube_job_spec_completions{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"} - kube_job_status_succeeded{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}  \u003e 0\n    for: 1h\n    labels:\n      severity: warning\n  - alert: KubeJobFailed\n    annotations:\n      message: Job {{ $labels.namespaces }}/{{ $labels.job }} failed to complete.\n    expr: |\n      kube_job_status_failed{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\"}  \u003e 0\n    for: 1h\n    labels:\n      severity: warning\n- name: kubernetes-resources\n  rules:\n  - alert: KubeCPUOvercommit\n    annotations:\n      message: Overcommited CPU resource requests on Pods, cannot tolerate node failure.\n    expr: |\n      sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)\n        /\n      sum(node:node_num_cpu:sum)\n        \u003e\n      (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)\n    for: 5m\n    labels:\n      severity: warning\n  - alert: KubeMemOvercommit\n    annotations:\n      message: Overcommited Memory resource requests on Pods, cannot tolerate node\n        failure.\n    expr: |\n      sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)\n        /\n      sum(node_memory_MemTotal)\n        \u003e\n      (count(node:node_num_cpu:sum)-1)\n        /\n      count(node:node_num_cpu:sum)\n    for: 5m\n    labels:\n      severity: warning\n  - alert: KubeCPUOvercommit\n    annotations:\n      message: Overcommited CPU resource request quota on Namespaces.\n    expr: |\n      sum(kube_resourcequota{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\", type=\"hard\", resource=\"requests.cpu\"})\n        /\n      sum(node:node_num_cpu:sum)\n        \u003e 1.5\n    for: 5m\n    labels:\n      severity: warning\n  - alert: KubeMemOvercommit\n    annotations:\n      message: Overcommited Memory resource request quota on Namespaces.\n    expr: |\n      sum(kube_resourcequota{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\", type=\"hard\", resource=\"requests.memory\"})\n        /\n      sum(node_memory_MemTotal{job=\"node-exporter\"})\n        \u003e 1.5\n    for: 5m\n    labels:\n      severity: warning\n  - alert: KubeQuotaExceeded\n    annotations:\n      message: '{{ printf \"%0.0f\" $value }}% usage of {{ $labels.resource }} in namespace\n        {{ $labels.namespace }}.'\n    expr: |\n      100 * kube_resourcequota{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\", type=\"used\"}\n        / ignoring(instance, job, type)\n      kube_resourcequota{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kube-state-metrics\", type=\"hard\"}\n        \u003e 90\n    for: 15m\n    labels:\n      severity: warning\n- name: kubernetes-storage\n  rules:\n  - alert: KubePersistentVolumeUsageCritical\n    annotations:\n      message: The persistent volume claimed by {{ $labels.persistentvolumeclaim }}\n        in namespace {{ $labels.namespace }} has {{ printf \"%0.0f\" $value }}% free.\n    expr: |\n      100 * kubelet_volume_stats_available_bytes{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kubelet\"}\n        /\n      kubelet_volume_stats_capacity_bytes{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kubelet\"}\n        \u003c 3\n    for: 1m\n    labels:\n      severity: critical\n  - alert: KubePersistentVolumeFullInFourDays\n    annotations:\n      message: Based on recent sampling, the persistent volume claimed by {{ $labels.persistentvolumeclaim\n        }} in namespace {{ $labels.namespace }} is expected to fill up within four\n        days. Currently {{ $value }} bytes are available.\n    expr: |\n      kubelet_volume_stats_available_bytes{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kubelet\"} and predict_linear(kubelet_volume_stats_available_bytes{namespace=~\"(openshift.*|kube.*|default|logging)\",job=\"kubelet\"}[6h], 4 * 24 * 3600) \u003c 0\n    for: 5m\n    labels:\n      severity: critical\n- name: kubernetes-system\n  rules:\n  - alert: KubeNodeNotReady\n    annotations:\n      message: '{{ $labels.node }} has been unready for more than an hour'\n    expr: |\n      kube_node_status_condition{job=\"kube-state-metrics\",condition=\"Ready\",status=\"true\"} == 0\n    for: 1h\n    labels:\n      severity: warning\n  - alert: KubeVersionMismatch\n    annotations:\n      message: There are {{ $value }} different versions of Kubernetes components\n        running.\n    expr: |\n      count(count(kubernetes_build_info{job!=\"kube-dns\"}) by (gitVersion)) \u003e 1\n    for: 1h\n    labels:\n      severity: warning\n  - alert: KubeClientErrors\n    annotations:\n      message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance\n        }}' is experiencing {{ printf \"%0.0f\" $value }}% errors.'\n    expr: |\n      (sum(rate(rest_client_requests_total{code!~\"2..|404\"}[5m])) by (instance, job)\n        /\n      sum(rate(rest_client_requests_total[5m])) by (instance, job))\n      * 100 \u003e 1\n    for: 15m\n    labels:\n      severity: warning\n  - alert: KubeClientErrors\n    annotations:\n      message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance\n        }}' is experiencing {{ printf \"%0.0f\" $value }} errors / sec.'\n    expr: |\n      sum(rate(ksm_scrape_error_total{job=\"kube-state-metrics\"}[5m])) by (instance, job) \u003e 0.1\n    for: 15m\n    labels:\n      severity: warning\n  - alert: KubeletTooManyPods\n    annotations:\n      message: Kubelet {{$labels.instance}} is running {{$value}} pods, close to the\n        limit of 110.\n    expr: |\n      kubelet_running_pod_count{job=\"kubelet\"} \u003e 100\n    for: 15m\n    labels:\n      severity: warning\n  - alert: KubeAPILatencyHigh\n    annotations:\n      message: The API server has a 99th percentile latency of {{ $value }} seconds\n        for {{$labels.verb}} {{$labels.resource}}.\n    expr: |\n      cluster_quantile:apiserver_request_latencies:histogram_quantile{job=\"apiserver\",quantile=\"0.99\",subresource!=\"log\",verb!~\"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$\"} \u003e 1\n    for: 10m\n    labels:\n      severity: warning\n  - alert: KubeAPILatencyHigh\n    annotations:\n      message: The API server has a 99th percentile latency of {{ $value }} seconds\n        for {{$labels.verb}} {{$labels.resource}}.\n    expr: |\n      cluster_quantile:apiserver_request_latencies:histogram_quantile{job=\"apiserver\",quantile=\"0.99\",subresource!=\"log\",verb!~\"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$\"} \u003e 4\n    for: 10m\n    labels:\n      severity: critical\n  - alert: KubeAPIErrorsHigh\n    annotations:\n      message: API server is erroring for {{ $value }}% of requests.\n    expr: |\n      sum(rate(apiserver_request_count{job=\"apiserver\",code=~\"^(?:5..)$\"}[5m])) without(instance, pod)\n        /\n      sum(rate(apiserver_request_count{job=\"apiserver\"}[5m])) without(instance, pod) * 100 \u003e 5\n    for: 10m\n    labels:\n      severity: critical\n  - alert: KubeAPIErrorsHigh\n    annotations:\n      message: API server is erroring for {{ $value }}% of requests.\n    expr: |\n      sum(rate(apiserver_request_count{job=\"apiserver\",code=~\"^(?:5..)$\"}[5m])) without(instance, pod)\n        /\n      sum(rate(apiserver_request_count{job=\"apiserver\"}[5m])) without(instance, pod) * 100 \u003e 5\n    for: 10m\n    labels:\n      severity: warning\n  - alert: KubeClientCertificateExpiration\n    annotations:\n      message: Kubernetes API certificate is expiring in less than 7 days.\n    expr: |\n      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"apiserver\"}[5m]))) \u003c 604800\n    labels:\n      severity: warning\n  - alert: KubeClientCertificateExpiration\n    annotations:\n      message: Kubernetes API certificate is expiring in less than 1 day.\n    expr: |\n      histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"apiserver\"}[5m]))) \u003c 86400\n    labels:\n      severity: critical\n- name: alertmanager.rules\n  rules:\n  - alert: AlertmanagerConfigInconsistent\n    annotations:\n      description: The configuration of the instances of the Alertmanager cluster\n        `{{$labels.service}}` are out of sync.\n      summary: Configuration out of sync\n    expr: |\n      count_values(\"config_hash\", alertmanager_config_hash{job=\"alertmanager-main\"}) BY (service) / ON(service) GROUP_LEFT() label_replace(prometheus_operator_alertmanager_spec_replicas{job=\"prometheus-operator\"}, \"service\", \"alertmanager-$1\", \"alertmanager\", \"(.*)\") != 1\n    for: 5m\n    labels:\n      severity: critical\n  - alert: AlertmanagerDownOrMissing\n    annotations:\n      description: An unexpected number of Alertmanagers are scraped or Alertmanagers\n        disappeared from discovery.\n      summary: Alertmanager down or missing\n    expr: |\n      label_replace(prometheus_operator_alertmanager_spec_replicas{job=\"prometheus-operator\"}, \"job\", \"alertmanager-$1\", \"alertmanager\", \"(.*)\") / ON(job) GROUP_RIGHT() sum(up{job=\"alertmanager-main\"}) BY (job) != 1\n    for: 5m\n    labels:\n      severity: warning\n  - alert: AlertmanagerFailedReload\n    annotations:\n      description: Reloading Alertmanager's configuration has failed for {{ $labels.namespace\n        }}/{{ $labels.pod}}.\n      summary: Alertmanager's configuration reload failed\n    expr: |\n      alertmanager_config_last_reload_successful{job=\"alertmanager-main\"} == 0\n    for: 10m\n    labels:\n      severity: warning\n- name: general.rules\n  rules:\n  - alert: TargetDown\n    annotations:\n      description: '{{ $value }}% of {{ $labels.job }} targets are down.'\n      summary: Targets are down\n    expr: 100 * (count(up == 0) BY (job) / count(up) BY (job)) \u003e 10\n    for: 10m\n    labels:\n      severity: warning\n  - alert: DeadMansSwitch\n    annotations:\n      description: This is a DeadMansSwitch meant to ensure that the entire Alerting\n        pipeline is functional.\n      summary: Alerting DeadMansSwitch\n    expr: vector(1)\n    labels:\n      severity: none\n- name: kube-prometheus-node-alerting.rules\n  rules:\n  - alert: NodeDiskRunningFull\n    annotations:\n      message: Device {{ $labels.device }} of node-exporter {{ $labels.namespace }}/{{\n        $labels.pod }} is running full within the next 24 hours.\n    expr: |\n      (node:node_filesystem_usage: \u003e 0.85) and (predict_linear(node:node_filesystem_avail:[6h], 3600 * 24) \u003c 0)\n    for: 30m\n    labels:\n      severity: warning\n  - alert: NodeDiskRunningFull\n    annotations:\n      message: Device {{ $labels.device }} of node-exporter {{ $labels.namespace }}/{{\n        $labels.pod }} is running full within the next 2 hours.\n    expr: |\n      (node:node_filesystem_usage: \u003e 0.85) and (predict_linear(node:node_filesystem_avail:[30m], 3600 * 2) \u003c 0)\n    for: 10m\n    labels:\n      severity: critical\n- name: prometheus.rules\n  rules:\n  - alert: PrometheusConfigReloadFailed\n    annotations:\n      description: Reloading Prometheus' configuration has failed for {{$labels.namespace}}/{{$labels.pod}}\n      summary: Reloading Promehteus' configuration failed\n    expr: |\n      prometheus_config_last_reload_successful{job=\"prometheus-k8s\"} == 0\n    for: 10m\n    labels:\n      severity: warning\n  - alert: PrometheusNotificationQueueRunningFull\n    annotations:\n      description: Prometheus' alert notification queue is running full for {{$labels.namespace}}/{{\n        $labels.pod}}\n      summary: Prometheus' alert notification queue is running full\n    expr: |\n      predict_linear(prometheus_notifications_queue_length{job=\"prometheus-k8s\"}[5m], 60 * 30) \u003e prometheus_notifications_queue_capacity{job=\"prometheus-k8s\"}\n    for: 10m\n    labels:\n      severity: warning\n  - alert: PrometheusErrorSendingAlerts\n    annotations:\n      description: Errors while sending alerts from Prometheus {{$labels.namespace}}/{{\n        $labels.pod}} to Alertmanager {{$labels.Alertmanager}}\n      summary: Errors while sending alert from Prometheus\n    expr: |\n      rate(prometheus_notifications_errors_total{job=\"prometheus-k8s\"}[5m]) / rate(prometheus_notifications_sent_total{job=\"prometheus-k8s\"}[5m]) \u003e 0.01\n    for: 10m\n    labels:\n      severity: warning\n  - alert: PrometheusErrorSendingAlerts\n    annotations:\n      description: Errors while sending alerts from Prometheus {{$labels.namespace}}/{{\n        $labels.pod}} to Alertmanager {{$labels.Alertmanager}}\n      summary: Errors while sending alerts from Prometheus\n    expr: |\n      rate(prometheus_notifications_errors_total{job=\"prometheus-k8s\"}[5m]) / rate(prometheus_notifications_sent_total{job=\"prometheus-k8s\"}[5m]) \u003e 0.03\n    for: 10m\n    labels:\n      severity: critical\n  - alert: PrometheusNotConnectedToAlertmanagers\n    annotations:\n      description: Prometheus {{ $labels.namespace }}/{{ $labels.pod}} is not connected\n        to any Alertmanagers\n      summary: Prometheus is not connected to any Alertmanagers\n    expr: |\n      prometheus_notifications_alertmanagers_discovered{job=\"prometheus-k8s\"} \u003c 1\n    for: 10m\n    labels:\n      severity: warning\n  - alert: PrometheusTSDBReloadsFailing\n    annotations:\n      description: '{{$labels.job}} at {{$labels.instance}} had {{$value | humanize}}\n        reload failures over the last four hours.'\n      summary: Prometheus has issues reloading data blocks from disk\n    expr: |\n      increase(prometheus_tsdb_reloads_failures_total{job=\"prometheus-k8s\"}[2h]) \u003e 0\n    for: 12h\n    labels:\n      severity: warning\n  - alert: PrometheusTSDBCompactionsFailing\n    annotations:\n      description: '{{$labels.job}} at {{$labels.instance}} had {{$value | humanize}}\n        compaction failures over the last four hours.'\n      summary: Prometheus has issues compacting sample blocks\n    expr: |\n      increase(prometheus_tsdb_compactions_failed_total{job=\"prometheus-k8s\"}[2h]) \u003e 0\n    for: 12h\n    labels:\n      severity: warning\n  - alert: PrometheusTSDBWALCorruptions\n    annotations:\n      description: '{{$labels.job}} at {{$labels.instance}} has a corrupted write-ahead\n        log (WAL).'\n      summary: Prometheus write-ahead log is corrupted\n    expr: |\n      tsdb_wal_corruptions_total{job=\"prometheus-k8s\"} \u003e 0\n    for: 4h\n    labels:\n      severity: warning\n  - alert: PrometheusNotIngestingSamples\n    annotations:\n      description: Prometheus {{ $labels.namespace }}/{{ $labels.pod}} isn't ingesting\n        samples.\n      summary: Prometheus isn't ingesting samples\n    expr: |\n      rate(prometheus_tsdb_head_samples_appended_total{job=\"prometheus-k8s\"}[5m]) \u003c= 0\n    for: 10m\n    labels:\n      severity: warning\n  - alert: PrometheusTargetScrapesDuplicate\n    annotations:\n      description: '{{$labels.namespace}}/{{$labels.pod}} has many samples rejected\n        due to duplicate timestamps but different values'\n      summary: Prometheus has many samples rejected\n    expr: |\n      increase(prometheus_target_scrapes_sample_duplicate_timestamp_total{job=\"prometheus-k8s\"}[5m]) \u003e 0\n    for: 10m\n    labels:\n      severity: warning\n"}}
